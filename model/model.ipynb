{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-29 18:22:24.743579: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-29 18:22:24.754614: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-29 18:22:24.767509: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-29 18:22:24.771230: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-29 18:22:24.780581: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-29 18:22:25.516200: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_42082/2038843518.py:11: FutureWarning: 'S' is deprecated and will be removed in a future version, please use 's' instead.\n",
      "  'time': pd.date_range(start='2023-01-01', periods=n_smoke_samples, freq='S'),  # Time range for smoke data\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "# Load the original \"no smoke\" data\n",
    "no_smoke_data = pd.read_csv('/home/hthnh/Desktop/project-khkt-thcs/noSmokeData.csv')  # Replace with actual file path if needed\n",
    "no_smoke_data['Label'] = 0  # Label for no-smoke data\n",
    "\n",
    "# Define the number of synthetic smoke samples and their characteristic ranges\n",
    "n_smoke_samples = 1000  # Number of synthetic smoke data points\n",
    "smoke_data = pd.DataFrame({\n",
    "    'time': pd.date_range(start='2023-01-01', periods=n_smoke_samples, freq='S'),  # Time range for smoke data\n",
    "    'Co': np.random.uniform(50, 200, n_smoke_samples),  # Elevated CO levels\n",
    "    'VOC': np.random.uniform(100, 1000, n_smoke_samples),  # Elevated VOC levels\n",
    "    'Temp': np.random.uniform(no_smoke_data['Temp'].min(), no_smoke_data['Temp'].max(), n_smoke_samples),\n",
    "    'Hum': np.random.uniform(no_smoke_data['Hum'].min(), no_smoke_data['Hum'].max(), n_smoke_samples),\n",
    "    'Label': 1  # Label for smoke data\n",
    "})\n",
    "\n",
    "# Combine no-smoke and synthetic smoke data\n",
    "combined_data = pd.concat([no_smoke_data, smoke_data], ignore_index=True)\n",
    "\n",
    "# Select the features for normalization\n",
    "features = ['Co', 'VOC', 'Temp', 'Hum']\n",
    "\n",
    "# Initialize and fit the scaler on the combined data\n",
    "scaler = joblib.load('/home/hthnh/Desktop/project-khkt-thcs/model/scaler.pkl')\n",
    "\n",
    "combined_data[features] = scaler.transform(combined_data[features])\n",
    "\n",
    "# Save the normalized combined data with labels to a CSV file\n",
    "combined_data.to_csv('normalized_no_smoke_and_smoke_data_with_labels.csv', index=False)\n",
    "data = combined_data\n",
    "# Display the first few rows of the normalized data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/home/hthnh/Desktop/project-khkt-thcs/model/processed_fit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['Co', 'VOC', 'Temp', 'Hum']]\n",
    "y = data['Label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = Sequential([\n",
    "    Dense(64, input_shape=(X_train.shape[1],), activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # Binary classification (normal vs smoke)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.save('base_smoke_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1730200981.870986   42082 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-29 18:23:01.895567: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "base_model = load_model('base_smoke_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9752 - loss: 0.5360 - val_accuracy: 0.9818 - val_loss: 0.4052\n",
      "Epoch 2/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9726 - loss: 0.3757 - val_accuracy: 0.9838 - val_loss: 0.2983\n",
      "Epoch 3/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9671 - loss: 0.2849 - val_accuracy: 0.9859 - val_loss: 0.2302\n",
      "Epoch 4/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9736 - loss: 0.2211 - val_accuracy: 0.9859 - val_loss: 0.1835\n",
      "Epoch 5/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9708 - loss: 0.1866 - val_accuracy: 0.9859 - val_loss: 0.1503\n",
      "Epoch 6/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9742 - loss: 0.1529 - val_accuracy: 0.9859 - val_loss: 0.1261\n",
      "Epoch 7/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9765 - loss: 0.1286 - val_accuracy: 0.9879 - val_loss: 0.1073\n",
      "Epoch 8/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9781 - loss: 0.1124 - val_accuracy: 0.9879 - val_loss: 0.0922\n",
      "Epoch 9/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9801 - loss: 0.0965 - val_accuracy: 0.9899 - val_loss: 0.0803\n",
      "Epoch 10/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9834 - loss: 0.0813 - val_accuracy: 0.9899 - val_loss: 0.0708\n",
      "Epoch 11/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9874 - loss: 0.0728 - val_accuracy: 0.9919 - val_loss: 0.0628\n",
      "Epoch 12/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9849 - loss: 0.0703 - val_accuracy: 0.9919 - val_loss: 0.0560\n",
      "Epoch 13/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9861 - loss: 0.0604 - val_accuracy: 0.9939 - val_loss: 0.0504\n",
      "Epoch 14/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9897 - loss: 0.0591 - val_accuracy: 0.9939 - val_loss: 0.0454\n",
      "Epoch 15/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9880 - loss: 0.0514 - val_accuracy: 0.9939 - val_loss: 0.0412\n",
      "Epoch 16/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9930 - loss: 0.0480 - val_accuracy: 0.9960 - val_loss: 0.0375\n",
      "Epoch 17/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9915 - loss: 0.0418 - val_accuracy: 0.9960 - val_loss: 0.0343\n",
      "Epoch 18/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9927 - loss: 0.0387 - val_accuracy: 0.9980 - val_loss: 0.0314\n",
      "Epoch 19/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9944 - loss: 0.0343 - val_accuracy: 0.9980 - val_loss: 0.0289\n",
      "Epoch 20/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9938 - loss: 0.0332 - val_accuracy: 0.9980 - val_loss: 0.0267\n",
      "Epoch 21/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9951 - loss: 0.0312 - val_accuracy: 0.9980 - val_loss: 0.0246\n",
      "Epoch 22/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9960 - loss: 0.0277 - val_accuracy: 0.9980 - val_loss: 0.0228\n",
      "Epoch 23/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9949 - loss: 0.0276 - val_accuracy: 0.9980 - val_loss: 0.0211\n",
      "Epoch 24/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 993us/step - accuracy: 0.9971 - loss: 0.0228 - val_accuracy: 0.9980 - val_loss: 0.0196\n",
      "Epoch 25/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 974us/step - accuracy: 0.9926 - loss: 0.0271 - val_accuracy: 0.9980 - val_loss: 0.0183\n",
      "Epoch 26/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 992us/step - accuracy: 0.9966 - loss: 0.0216 - val_accuracy: 0.9980 - val_loss: 0.0170\n",
      "Epoch 27/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9973 - loss: 0.0188 - val_accuracy: 0.9980 - val_loss: 0.0159\n",
      "Epoch 28/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9962 - loss: 0.0218 - val_accuracy: 0.9980 - val_loss: 0.0148\n",
      "Epoch 29/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9960 - loss: 0.0198 - val_accuracy: 0.9980 - val_loss: 0.0139\n",
      "Epoch 30/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 997us/step - accuracy: 0.9954 - loss: 0.0195 - val_accuracy: 1.0000 - val_loss: 0.0130\n",
      "Epoch 31/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9996 - loss: 0.0149 - val_accuracy: 1.0000 - val_loss: 0.0122\n",
      "Epoch 32/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9991 - loss: 0.0142 - val_accuracy: 1.0000 - val_loss: 0.0115\n",
      "Epoch 33/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9994 - loss: 0.0141 - val_accuracy: 1.0000 - val_loss: 0.0108\n",
      "Epoch 34/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9997 - loss: 0.0140 - val_accuracy: 1.0000 - val_loss: 0.0101\n",
      "Epoch 35/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9993 - loss: 0.0134 - val_accuracy: 1.0000 - val_loss: 0.0096\n",
      "Epoch 36/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9999 - loss: 0.0118 - val_accuracy: 1.0000 - val_loss: 0.0090\n",
      "Epoch 37/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0103 - val_accuracy: 1.0000 - val_loss: 0.0085\n",
      "Epoch 38/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9997 - loss: 0.0096 - val_accuracy: 1.0000 - val_loss: 0.0080\n",
      "Epoch 39/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 980us/step - accuracy: 0.9997 - loss: 0.0099 - val_accuracy: 1.0000 - val_loss: 0.0076\n",
      "Epoch 40/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9997 - loss: 0.0101 - val_accuracy: 1.0000 - val_loss: 0.0072\n",
      "Epoch 41/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9998 - loss: 0.0094 - val_accuracy: 1.0000 - val_loss: 0.0068\n",
      "Epoch 42/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9985 - loss: 0.0087 - val_accuracy: 1.0000 - val_loss: 0.0064\n",
      "Epoch 43/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0098 - val_accuracy: 1.0000 - val_loss: 0.0061\n",
      "Epoch 44/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0072 - val_accuracy: 1.0000 - val_loss: 0.0058\n",
      "Epoch 45/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0063 - val_accuracy: 1.0000 - val_loss: 0.0055\n",
      "Epoch 46/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0080 - val_accuracy: 1.0000 - val_loss: 0.0052\n",
      "Epoch 47/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0060 - val_accuracy: 1.0000 - val_loss: 0.0049\n",
      "Epoch 48/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0059 - val_accuracy: 1.0000 - val_loss: 0.0047\n",
      "Epoch 49/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0065 - val_accuracy: 1.0000 - val_loss: 0.0044\n",
      "Epoch 50/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0059 - val_accuracy: 1.0000 - val_loss: 0.0042\n",
      "Epoch 51/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0080 - val_accuracy: 1.0000 - val_loss: 0.0040\n",
      "Epoch 52/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 1.0000 - val_loss: 0.0038\n",
      "Epoch 53/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0058 - val_accuracy: 1.0000 - val_loss: 0.0036\n",
      "Epoch 54/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 1.0000 - val_loss: 0.0035\n",
      "Epoch 55/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 1.0000 - val_loss: 0.0033\n",
      "Epoch 56/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0048 - val_accuracy: 1.0000 - val_loss: 0.0032\n",
      "Epoch 57/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 1.0000 - val_loss: 0.0030\n",
      "Epoch 58/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 1.0000 - val_loss: 0.0029\n",
      "Epoch 59/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 1.0000 - val_loss: 0.0027\n",
      "Epoch 60/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 1.0000 - val_loss: 0.0026\n",
      "Epoch 61/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 1.0000 - val_loss: 0.0025\n",
      "Epoch 62/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 1.0000 - val_loss: 0.0024\n",
      "Epoch 63/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 1.0000 - val_loss: 0.0023\n",
      "Epoch 64/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 1.0000 - val_loss: 0.0022\n",
      "Epoch 65/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 1.0000 - val_loss: 0.0021\n",
      "Epoch 66/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 1.0000 - val_loss: 0.0020\n",
      "Epoch 67/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 1.0000 - val_loss: 0.0019\n",
      "Epoch 68/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955us/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 1.0000 - val_loss: 0.0018\n",
      "Epoch 69/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 1.0000 - val_loss: 0.0017\n",
      "Epoch 70/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 1.0000 - val_loss: 0.0017\n",
      "Epoch 71/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971us/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 1.0000 - val_loss: 0.0016\n",
      "Epoch 72/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 1.0000 - val_loss: 0.0015\n",
      "Epoch 73/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 1.0000 - val_loss: 0.0015\n",
      "Epoch 74/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 966us/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 1.0000 - val_loss: 0.0014\n",
      "Epoch 75/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 1.0000 - val_loss: 0.0014\n",
      "Epoch 76/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 1.0000 - val_loss: 0.0013\n",
      "Epoch 77/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
      "Epoch 78/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
      "Epoch 79/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 963us/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
      "Epoch 80/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
      "Epoch 81/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 947us/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
      "Epoch 82/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 0.0010\n",
      "Epoch 83/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 1.0000 - val_loss: 9.7301e-04\n",
      "Epoch 84/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971us/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 9.3166e-04\n",
      "Epoch 85/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989us/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 1.0000 - val_loss: 8.9608e-04\n",
      "Epoch 86/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 8.6096e-04\n",
      "Epoch 87/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 8.2480e-04\n",
      "Epoch 88/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 1.0000 - val_loss: 7.9431e-04\n",
      "Epoch 89/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 7.6346e-04\n",
      "Epoch 90/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 980us/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 1.0000 - val_loss: 7.3267e-04\n",
      "Epoch 91/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 9.4148e-04 - val_accuracy: 1.0000 - val_loss: 7.0603e-04\n",
      "Epoch 92/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 988us/step - accuracy: 1.0000 - loss: 9.1366e-04 - val_accuracy: 1.0000 - val_loss: 6.7923e-04\n",
      "Epoch 93/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 9.7265e-04 - val_accuracy: 1.0000 - val_loss: 6.5210e-04\n",
      "Epoch 94/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998us/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 6.2513e-04\n",
      "Epoch 95/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 7.3645e-04 - val_accuracy: 1.0000 - val_loss: 6.0351e-04\n",
      "Epoch 96/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 985us/step - accuracy: 1.0000 - loss: 7.5024e-04 - val_accuracy: 1.0000 - val_loss: 5.8104e-04\n",
      "Epoch 97/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989us/step - accuracy: 1.0000 - loss: 8.3326e-04 - val_accuracy: 1.0000 - val_loss: 5.6000e-04\n",
      "Epoch 98/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 974us/step - accuracy: 1.0000 - loss: 9.4209e-04 - val_accuracy: 1.0000 - val_loss: 5.3718e-04\n",
      "Epoch 99/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 975us/step - accuracy: 1.0000 - loss: 7.9401e-04 - val_accuracy: 1.0000 - val_loss: 5.1658e-04\n",
      "Epoch 100/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 6.3894e-04 - val_accuracy: 1.0000 - val_loss: 4.9498e-04\n",
      "Epoch 101/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999us/step - accuracy: 1.0000 - loss: 7.7889e-04 - val_accuracy: 1.0000 - val_loss: 4.7940e-04\n",
      "Epoch 102/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 7.5198e-04 - val_accuracy: 1.0000 - val_loss: 4.6031e-04\n",
      "Epoch 103/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 6.9326e-04 - val_accuracy: 1.0000 - val_loss: 4.4238e-04\n",
      "Epoch 104/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 983us/step - accuracy: 1.0000 - loss: 5.2663e-04 - val_accuracy: 1.0000 - val_loss: 4.2493e-04\n",
      "Epoch 105/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 953us/step - accuracy: 1.0000 - loss: 4.8646e-04 - val_accuracy: 1.0000 - val_loss: 4.1286e-04\n",
      "Epoch 106/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971us/step - accuracy: 1.0000 - loss: 6.5019e-04 - val_accuracy: 1.0000 - val_loss: 3.9775e-04\n",
      "Epoch 107/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 969us/step - accuracy: 1.0000 - loss: 4.1450e-04 - val_accuracy: 1.0000 - val_loss: 3.8215e-04\n",
      "Epoch 108/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 5.9240e-04 - val_accuracy: 1.0000 - val_loss: 3.6842e-04\n",
      "Epoch 109/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 5.1973e-04 - val_accuracy: 1.0000 - val_loss: 3.5401e-04\n",
      "Epoch 110/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 4.3733e-04 - val_accuracy: 1.0000 - val_loss: 3.4147e-04\n",
      "Epoch 111/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996us/step - accuracy: 1.0000 - loss: 3.7063e-04 - val_accuracy: 1.0000 - val_loss: 3.2802e-04\n",
      "Epoch 112/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 4.3724e-04 - val_accuracy: 1.0000 - val_loss: 3.1702e-04\n",
      "Epoch 113/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998us/step - accuracy: 1.0000 - loss: 4.0896e-04 - val_accuracy: 1.0000 - val_loss: 3.0644e-04\n",
      "Epoch 114/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.2647e-04 - val_accuracy: 1.0000 - val_loss: 2.9497e-04\n",
      "Epoch 115/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 951us/step - accuracy: 1.0000 - loss: 4.9072e-04 - val_accuracy: 1.0000 - val_loss: 2.8314e-04\n",
      "Epoch 116/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 944us/step - accuracy: 1.0000 - loss: 3.3108e-04 - val_accuracy: 1.0000 - val_loss: 2.7203e-04\n",
      "Epoch 117/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 951us/step - accuracy: 1.0000 - loss: 4.5834e-04 - val_accuracy: 1.0000 - val_loss: 2.6387e-04\n",
      "Epoch 118/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 4.0617e-04 - val_accuracy: 1.0000 - val_loss: 2.5341e-04\n",
      "Epoch 119/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 983us/step - accuracy: 1.0000 - loss: 3.9419e-04 - val_accuracy: 1.0000 - val_loss: 2.4496e-04\n",
      "Epoch 120/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998us/step - accuracy: 1.0000 - loss: 4.2043e-04 - val_accuracy: 1.0000 - val_loss: 2.3536e-04\n",
      "Epoch 121/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 992us/step - accuracy: 1.0000 - loss: 3.2508e-04 - val_accuracy: 1.0000 - val_loss: 2.2683e-04\n",
      "Epoch 122/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.4887e-04 - val_accuracy: 1.0000 - val_loss: 2.1842e-04\n",
      "Epoch 123/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 3.3755e-04 - val_accuracy: 1.0000 - val_loss: 2.1251e-04\n",
      "Epoch 124/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 976us/step - accuracy: 1.0000 - loss: 3.1629e-04 - val_accuracy: 1.0000 - val_loss: 2.0398e-04\n",
      "Epoch 125/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 994us/step - accuracy: 1.0000 - loss: 3.0784e-04 - val_accuracy: 1.0000 - val_loss: 1.9666e-04\n",
      "Epoch 126/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 973us/step - accuracy: 1.0000 - loss: 2.4428e-04 - val_accuracy: 1.0000 - val_loss: 1.8948e-04\n",
      "Epoch 127/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.4400e-04 - val_accuracy: 1.0000 - val_loss: 1.8368e-04\n",
      "Epoch 128/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step - accuracy: 1.0000 - loss: 2.4851e-04 - val_accuracy: 1.0000 - val_loss: 1.7705e-04\n",
      "Epoch 129/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.2841e-04 - val_accuracy: 1.0000 - val_loss: 1.7004e-04\n",
      "Epoch 130/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 954us/step - accuracy: 1.0000 - loss: 2.5633e-04 - val_accuracy: 1.0000 - val_loss: 1.6505e-04\n",
      "Epoch 131/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970us/step - accuracy: 1.0000 - loss: 2.1763e-04 - val_accuracy: 1.0000 - val_loss: 1.5880e-04\n",
      "Epoch 132/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - accuracy: 1.0000 - loss: 2.1327e-04 - val_accuracy: 1.0000 - val_loss: 1.5335e-04\n",
      "Epoch 133/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 997us/step - accuracy: 1.0000 - loss: 1.9509e-04 - val_accuracy: 1.0000 - val_loss: 1.4822e-04\n",
      "Epoch 134/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0572e-04 - val_accuracy: 1.0000 - val_loss: 1.4266e-04\n",
      "Epoch 135/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.0762e-04 - val_accuracy: 1.0000 - val_loss: 1.3800e-04\n",
      "Epoch 136/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 3.0777e-04 - val_accuracy: 1.0000 - val_loss: 1.3254e-04\n",
      "Epoch 137/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.8992e-04 - val_accuracy: 1.0000 - val_loss: 1.2806e-04\n",
      "Epoch 138/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.5383e-04 - val_accuracy: 1.0000 - val_loss: 1.2404e-04\n",
      "Epoch 139/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 987us/step - accuracy: 1.0000 - loss: 1.5314e-04 - val_accuracy: 1.0000 - val_loss: 1.1975e-04\n",
      "Epoch 140/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 987us/step - accuracy: 1.0000 - loss: 1.7094e-04 - val_accuracy: 1.0000 - val_loss: 1.1560e-04\n",
      "Epoch 141/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - accuracy: 1.0000 - loss: 1.9029e-04 - val_accuracy: 1.0000 - val_loss: 1.1126e-04\n",
      "Epoch 142/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.5620e-04 - val_accuracy: 1.0000 - val_loss: 1.0742e-04\n",
      "Epoch 143/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.4903e-04 - val_accuracy: 1.0000 - val_loss: 1.0356e-04\n",
      "Epoch 144/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 972us/step - accuracy: 1.0000 - loss: 1.1400e-04 - val_accuracy: 1.0000 - val_loss: 1.0011e-04\n",
      "Epoch 145/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.0684e-04 - val_accuracy: 1.0000 - val_loss: 9.6240e-05\n",
      "Epoch 146/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.1094e-04 - val_accuracy: 1.0000 - val_loss: 9.3989e-05\n",
      "Epoch 147/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 995us/step - accuracy: 1.0000 - loss: 1.4160e-04 - val_accuracy: 1.0000 - val_loss: 9.0662e-05\n",
      "Epoch 148/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 988us/step - accuracy: 1.0000 - loss: 1.4015e-04 - val_accuracy: 1.0000 - val_loss: 8.7401e-05\n",
      "Epoch 149/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.1116e-04 - val_accuracy: 1.0000 - val_loss: 8.4336e-05\n",
      "Epoch 150/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.0895e-04 - val_accuracy: 1.0000 - val_loss: 8.1299e-05\n",
      "Epoch 151/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.1428e-04 - val_accuracy: 1.0000 - val_loss: 7.8829e-05\n",
      "Epoch 152/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 986us/step - accuracy: 1.0000 - loss: 1.2306e-04 - val_accuracy: 1.0000 - val_loss: 7.6020e-05\n",
      "Epoch 153/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step - accuracy: 1.0000 - loss: 9.3099e-05 - val_accuracy: 1.0000 - val_loss: 7.3345e-05\n",
      "Epoch 154/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 997us/step - accuracy: 1.0000 - loss: 9.0789e-05 - val_accuracy: 1.0000 - val_loss: 7.0731e-05\n",
      "Epoch 155/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step - accuracy: 1.0000 - loss: 8.0752e-05 - val_accuracy: 1.0000 - val_loss: 6.8568e-05\n",
      "Epoch 156/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 997us/step - accuracy: 1.0000 - loss: 9.7512e-05 - val_accuracy: 1.0000 - val_loss: 6.6319e-05\n",
      "Epoch 157/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.4413e-04 - val_accuracy: 1.0000 - val_loss: 6.3794e-05\n",
      "Epoch 158/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 8.7885e-05 - val_accuracy: 1.0000 - val_loss: 6.1581e-05\n",
      "Epoch 159/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step - accuracy: 1.0000 - loss: 1.4921e-04 - val_accuracy: 1.0000 - val_loss: 5.9479e-05\n",
      "Epoch 160/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 9.0841e-05 - val_accuracy: 1.0000 - val_loss: 5.7371e-05\n",
      "Epoch 161/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 969us/step - accuracy: 1.0000 - loss: 9.4584e-05 - val_accuracy: 1.0000 - val_loss: 5.5428e-05\n",
      "Epoch 162/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 973us/step - accuracy: 1.0000 - loss: 7.2668e-05 - val_accuracy: 1.0000 - val_loss: 5.3550e-05\n",
      "Epoch 163/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step - accuracy: 1.0000 - loss: 6.6930e-05 - val_accuracy: 1.0000 - val_loss: 5.1488e-05\n",
      "Epoch 164/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.0706e-04 - val_accuracy: 1.0000 - val_loss: 5.0215e-05\n",
      "Epoch 165/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 886us/step - accuracy: 1.0000 - loss: 5.8823e-05 - val_accuracy: 1.0000 - val_loss: 4.8305e-05\n",
      "Epoch 166/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.2377e-05 - val_accuracy: 1.0000 - val_loss: 4.6774e-05\n",
      "Epoch 167/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998us/step - accuracy: 1.0000 - loss: 6.3621e-05 - val_accuracy: 1.0000 - val_loss: 4.5490e-05\n",
      "Epoch 168/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step - accuracy: 1.0000 - loss: 7.3496e-05 - val_accuracy: 1.0000 - val_loss: 4.3868e-05\n",
      "Epoch 169/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 7.7628e-05 - val_accuracy: 1.0000 - val_loss: 4.2235e-05\n",
      "Epoch 170/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 981us/step - accuracy: 1.0000 - loss: 4.9203e-05 - val_accuracy: 1.0000 - val_loss: 4.0550e-05\n",
      "Epoch 171/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step - accuracy: 1.0000 - loss: 7.1331e-05 - val_accuracy: 1.0000 - val_loss: 3.9373e-05\n",
      "Epoch 172/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971us/step - accuracy: 1.0000 - loss: 5.7285e-05 - val_accuracy: 1.0000 - val_loss: 3.8105e-05\n",
      "Epoch 173/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 6.1525e-05 - val_accuracy: 1.0000 - val_loss: 3.6672e-05\n",
      "Epoch 174/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 5.7343e-05 - val_accuracy: 1.0000 - val_loss: 3.5547e-05\n",
      "Epoch 175/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 6.0791e-05 - val_accuracy: 1.0000 - val_loss: 3.4346e-05\n",
      "Epoch 176/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 985us/step - accuracy: 1.0000 - loss: 5.6489e-05 - val_accuracy: 1.0000 - val_loss: 3.3156e-05\n",
      "Epoch 177/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 994us/step - accuracy: 1.0000 - loss: 4.7857e-05 - val_accuracy: 1.0000 - val_loss: 3.1969e-05\n",
      "Epoch 178/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 4.9727e-05 - val_accuracy: 1.0000 - val_loss: 3.0922e-05\n",
      "Epoch 179/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 973us/step - accuracy: 1.0000 - loss: 4.0910e-05 - val_accuracy: 1.0000 - val_loss: 2.9936e-05\n",
      "Epoch 180/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 3.9477e-05 - val_accuracy: 1.0000 - val_loss: 2.9047e-05\n",
      "Epoch 181/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 972us/step - accuracy: 1.0000 - loss: 4.6248e-05 - val_accuracy: 1.0000 - val_loss: 2.8084e-05\n",
      "Epoch 182/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 961us/step - accuracy: 1.0000 - loss: 4.6763e-05 - val_accuracy: 1.0000 - val_loss: 2.7074e-05\n",
      "Epoch 183/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 4.0478e-05 - val_accuracy: 1.0000 - val_loss: 2.6080e-05\n",
      "Epoch 184/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 3.0210e-05 - val_accuracy: 1.0000 - val_loss: 2.5282e-05\n",
      "Epoch 185/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 983us/step - accuracy: 1.0000 - loss: 4.5078e-05 - val_accuracy: 1.0000 - val_loss: 2.4557e-05\n",
      "Epoch 186/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 980us/step - accuracy: 1.0000 - loss: 3.4271e-05 - val_accuracy: 1.0000 - val_loss: 2.3719e-05\n",
      "Epoch 187/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - accuracy: 1.0000 - loss: 2.8569e-05 - val_accuracy: 1.0000 - val_loss: 2.2864e-05\n",
      "Epoch 188/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.8646e-05 - val_accuracy: 1.0000 - val_loss: 2.2159e-05\n",
      "Epoch 189/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 973us/step - accuracy: 1.0000 - loss: 3.3660e-05 - val_accuracy: 1.0000 - val_loss: 2.1437e-05\n",
      "Epoch 190/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 977us/step - accuracy: 1.0000 - loss: 3.1356e-05 - val_accuracy: 1.0000 - val_loss: 2.0787e-05\n",
      "Epoch 191/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 963us/step - accuracy: 1.0000 - loss: 3.0141e-05 - val_accuracy: 1.0000 - val_loss: 2.0085e-05\n",
      "Epoch 192/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.8089e-05 - val_accuracy: 1.0000 - val_loss: 1.9353e-05\n",
      "Epoch 193/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7792e-05 - val_accuracy: 1.0000 - val_loss: 1.8589e-05\n",
      "Epoch 194/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 993us/step - accuracy: 1.0000 - loss: 2.4095e-05 - val_accuracy: 1.0000 - val_loss: 1.8043e-05\n",
      "Epoch 195/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999us/step - accuracy: 1.0000 - loss: 4.0442e-05 - val_accuracy: 1.0000 - val_loss: 1.7532e-05\n",
      "Epoch 196/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.8742e-05 - val_accuracy: 1.0000 - val_loss: 1.6925e-05\n",
      "Epoch 197/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.1472e-05 - val_accuracy: 1.0000 - val_loss: 1.6166e-05\n",
      "Epoch 198/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 962us/step - accuracy: 1.0000 - loss: 2.4605e-05 - val_accuracy: 1.0000 - val_loss: 1.5834e-05\n",
      "Epoch 199/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 985us/step - accuracy: 1.0000 - loss: 2.7357e-05 - val_accuracy: 1.0000 - val_loss: 1.5319e-05\n",
      "Epoch 200/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 995us/step - accuracy: 1.0000 - loss: 1.6884e-05 - val_accuracy: 1.0000 - val_loss: 1.4682e-05\n",
      "Epoch 201/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.7479e-05 - val_accuracy: 1.0000 - val_loss: 1.4285e-05\n",
      "Epoch 202/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.9438e-05 - val_accuracy: 1.0000 - val_loss: 1.3842e-05\n",
      "Epoch 203/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 958us/step - accuracy: 1.0000 - loss: 1.6274e-05 - val_accuracy: 1.0000 - val_loss: 1.3252e-05\n",
      "Epoch 204/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.0281e-05 - val_accuracy: 1.0000 - val_loss: 1.2987e-05\n",
      "Epoch 205/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 979us/step - accuracy: 1.0000 - loss: 1.6632e-05 - val_accuracy: 1.0000 - val_loss: 1.2383e-05\n",
      "Epoch 206/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6373e-05 - val_accuracy: 1.0000 - val_loss: 1.2086e-05\n",
      "Epoch 207/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 995us/step - accuracy: 1.0000 - loss: 1.9306e-05 - val_accuracy: 1.0000 - val_loss: 1.1763e-05\n",
      "Epoch 208/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.6666e-05 - val_accuracy: 1.0000 - val_loss: 1.1267e-05\n",
      "Epoch 209/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.2972e-05 - val_accuracy: 1.0000 - val_loss: 1.0854e-05\n",
      "Epoch 210/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 993us/step - accuracy: 1.0000 - loss: 1.6479e-05 - val_accuracy: 1.0000 - val_loss: 1.0606e-05\n",
      "Epoch 211/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.6096e-05 - val_accuracy: 1.0000 - val_loss: 1.0271e-05\n",
      "Epoch 212/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 987us/step - accuracy: 1.0000 - loss: 1.4431e-05 - val_accuracy: 1.0000 - val_loss: 9.9420e-06\n",
      "Epoch 213/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 993us/step - accuracy: 1.0000 - loss: 1.3992e-05 - val_accuracy: 1.0000 - val_loss: 9.6122e-06\n",
      "Epoch 214/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.7629e-05 - val_accuracy: 1.0000 - val_loss: 9.2642e-06\n",
      "Epoch 215/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.5173e-05 - val_accuracy: 1.0000 - val_loss: 8.9246e-06\n",
      "Epoch 216/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.1161e-05 - val_accuracy: 1.0000 - val_loss: 8.6287e-06\n",
      "Epoch 217/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1547e-05 - val_accuracy: 1.0000 - val_loss: 8.3347e-06\n",
      "Epoch 218/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.1235e-05 - val_accuracy: 1.0000 - val_loss: 8.1099e-06\n",
      "Epoch 219/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2663e-05 - val_accuracy: 1.0000 - val_loss: 7.8477e-06\n",
      "Epoch 220/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 979us/step - accuracy: 1.0000 - loss: 1.2800e-05 - val_accuracy: 1.0000 - val_loss: 7.5586e-06\n",
      "Epoch 221/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998us/step - accuracy: 1.0000 - loss: 1.1174e-05 - val_accuracy: 1.0000 - val_loss: 7.3197e-06\n",
      "Epoch 222/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.5248e-05 - val_accuracy: 1.0000 - val_loss: 7.0850e-06\n",
      "Epoch 223/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 983us/step - accuracy: 1.0000 - loss: 1.2571e-05 - val_accuracy: 1.0000 - val_loss: 6.8503e-06\n",
      "Epoch 224/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 9.5408e-06 - val_accuracy: 1.0000 - val_loss: 6.6171e-06\n",
      "Epoch 225/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 8.7448e-06 - val_accuracy: 1.0000 - val_loss: 6.4229e-06\n",
      "Epoch 226/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.4136e-05 - val_accuracy: 1.0000 - val_loss: 6.2046e-06\n",
      "Epoch 227/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 9.4706e-06 - val_accuracy: 1.0000 - val_loss: 5.9963e-06\n",
      "Epoch 228/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.1091e-05 - val_accuracy: 1.0000 - val_loss: 5.7798e-06\n",
      "Epoch 229/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - accuracy: 1.0000 - loss: 9.8292e-06 - val_accuracy: 1.0000 - val_loss: 5.6319e-06\n",
      "Epoch 230/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 993us/step - accuracy: 1.0000 - loss: 9.8021e-06 - val_accuracy: 1.0000 - val_loss: 5.4063e-06\n",
      "Epoch 231/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 985us/step - accuracy: 1.0000 - loss: 1.1307e-05 - val_accuracy: 1.0000 - val_loss: 5.2215e-06\n",
      "Epoch 232/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 8.4456e-06 - val_accuracy: 1.0000 - val_loss: 5.0450e-06\n",
      "Epoch 233/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.0127e-05 - val_accuracy: 1.0000 - val_loss: 4.9151e-06\n",
      "Epoch 234/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 7.5197e-06 - val_accuracy: 1.0000 - val_loss: 4.7446e-06\n",
      "Epoch 235/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 981us/step - accuracy: 1.0000 - loss: 8.9538e-06 - val_accuracy: 1.0000 - val_loss: 4.5872e-06\n",
      "Epoch 236/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 6.8178e-06 - val_accuracy: 1.0000 - val_loss: 4.4435e-06\n",
      "Epoch 237/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 7.3018e-06 - val_accuracy: 1.0000 - val_loss: 4.3035e-06\n",
      "Epoch 238/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 7.7557e-06 - val_accuracy: 1.0000 - val_loss: 4.1523e-06\n",
      "Epoch 239/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 6.2211e-06 - val_accuracy: 1.0000 - val_loss: 4.0161e-06\n",
      "Epoch 240/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 5.1245e-06 - val_accuracy: 1.0000 - val_loss: 3.8670e-06\n",
      "Epoch 241/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 965us/step - accuracy: 1.0000 - loss: 1.0875e-05 - val_accuracy: 1.0000 - val_loss: 3.7721e-06\n",
      "Epoch 242/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.0598e-05 - val_accuracy: 1.0000 - val_loss: 3.6409e-06\n",
      "Epoch 243/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step - accuracy: 1.0000 - loss: 6.2598e-06 - val_accuracy: 1.0000 - val_loss: 3.5114e-06\n",
      "Epoch 244/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 969us/step - accuracy: 1.0000 - loss: 5.5141e-06 - val_accuracy: 1.0000 - val_loss: 3.4095e-06\n",
      "Epoch 245/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 986us/step - accuracy: 1.0000 - loss: 6.5969e-06 - val_accuracy: 1.0000 - val_loss: 3.3075e-06\n",
      "Epoch 246/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 5.9596e-06 - val_accuracy: 1.0000 - val_loss: 3.1919e-06\n",
      "Epoch 247/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 994us/step - accuracy: 1.0000 - loss: 5.4073e-06 - val_accuracy: 1.0000 - val_loss: 3.0919e-06\n",
      "Epoch 248/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 4.6228e-06 - val_accuracy: 1.0000 - val_loss: 2.9888e-06\n",
      "Epoch 249/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 4.8189e-06 - val_accuracy: 1.0000 - val_loss: 2.8990e-06\n",
      "Epoch 250/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 4.5551e-06 - val_accuracy: 1.0000 - val_loss: 2.7807e-06\n",
      "Epoch 251/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 4.4283e-06 - val_accuracy: 1.0000 - val_loss: 2.7336e-06\n",
      "Epoch 252/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 4.6680e-06 - val_accuracy: 1.0000 - val_loss: 2.6277e-06\n",
      "Epoch 253/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996us/step - accuracy: 1.0000 - loss: 4.6542e-06 - val_accuracy: 1.0000 - val_loss: 2.5549e-06\n",
      "Epoch 254/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - accuracy: 1.0000 - loss: 3.8304e-06 - val_accuracy: 1.0000 - val_loss: 2.4689e-06\n",
      "Epoch 255/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - accuracy: 1.0000 - loss: 3.3155e-06 - val_accuracy: 1.0000 - val_loss: 2.3798e-06\n",
      "Epoch 256/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 3.4199e-06 - val_accuracy: 1.0000 - val_loss: 2.3097e-06\n",
      "Epoch 257/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 7.1279e-06 - val_accuracy: 1.0000 - val_loss: 2.2338e-06\n",
      "Epoch 258/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 5.4466e-06 - val_accuracy: 1.0000 - val_loss: 2.1532e-06\n",
      "Epoch 259/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.6905e-06 - val_accuracy: 1.0000 - val_loss: 2.0600e-06\n",
      "Epoch 260/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 994us/step - accuracy: 1.0000 - loss: 3.7239e-06 - val_accuracy: 1.0000 - val_loss: 2.0262e-06\n",
      "Epoch 261/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 993us/step - accuracy: 1.0000 - loss: 4.2113e-06 - val_accuracy: 1.0000 - val_loss: 1.9525e-06\n",
      "Epoch 262/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.7693e-06 - val_accuracy: 1.0000 - val_loss: 1.8851e-06\n",
      "Epoch 263/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 3.4508e-06 - val_accuracy: 1.0000 - val_loss: 1.8435e-06\n",
      "Epoch 264/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989us/step - accuracy: 1.0000 - loss: 7.1205e-06 - val_accuracy: 1.0000 - val_loss: 1.7788e-06\n",
      "Epoch 265/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 4.6851e-06 - val_accuracy: 1.0000 - val_loss: 1.7140e-06\n",
      "Epoch 266/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.6677e-06 - val_accuracy: 1.0000 - val_loss: 1.6602e-06\n",
      "Epoch 267/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 5.9520e-06 - val_accuracy: 1.0000 - val_loss: 1.6055e-06\n",
      "Epoch 268/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 973us/step - accuracy: 1.0000 - loss: 2.5534e-06 - val_accuracy: 1.0000 - val_loss: 1.5343e-06\n",
      "Epoch 269/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971us/step - accuracy: 1.0000 - loss: 2.9437e-06 - val_accuracy: 1.0000 - val_loss: 1.4987e-06\n",
      "Epoch 270/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 6.1438e-06 - val_accuracy: 1.0000 - val_loss: 1.4541e-06\n",
      "Epoch 271/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.7466e-06 - val_accuracy: 1.0000 - val_loss: 1.4061e-06\n",
      "Epoch 272/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4357e-06 - val_accuracy: 1.0000 - val_loss: 1.3641e-06\n",
      "Epoch 273/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 976us/step - accuracy: 1.0000 - loss: 2.5212e-06 - val_accuracy: 1.0000 - val_loss: 1.3245e-06\n",
      "Epoch 274/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.2271e-06 - val_accuracy: 1.0000 - val_loss: 1.2722e-06\n",
      "Epoch 275/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.2291e-06 - val_accuracy: 1.0000 - val_loss: 1.2352e-06\n",
      "Epoch 276/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.3879e-06 - val_accuracy: 1.0000 - val_loss: 1.1998e-06\n",
      "Epoch 277/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989us/step - accuracy: 1.0000 - loss: 3.1901e-06 - val_accuracy: 1.0000 - val_loss: 1.1610e-06\n",
      "Epoch 278/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.1230e-06 - val_accuracy: 1.0000 - val_loss: 1.1227e-06\n",
      "Epoch 279/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 965us/step - accuracy: 1.0000 - loss: 1.4520e-06 - val_accuracy: 1.0000 - val_loss: 1.0821e-06\n",
      "Epoch 280/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 969us/step - accuracy: 1.0000 - loss: 1.4084e-06 - val_accuracy: 1.0000 - val_loss: 1.0534e-06\n",
      "Epoch 281/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 980us/step - accuracy: 1.0000 - loss: 1.7639e-06 - val_accuracy: 1.0000 - val_loss: 1.0280e-06\n",
      "Epoch 282/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5777e-06 - val_accuracy: 1.0000 - val_loss: 9.9222e-07\n",
      "Epoch 283/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 949us/step - accuracy: 1.0000 - loss: 1.9311e-06 - val_accuracy: 1.0000 - val_loss: 9.6284e-07\n",
      "Epoch 284/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.5326e-06 - val_accuracy: 1.0000 - val_loss: 9.3246e-07\n",
      "Epoch 285/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.8273e-06 - val_accuracy: 1.0000 - val_loss: 9.0017e-07\n",
      "Epoch 286/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 997us/step - accuracy: 1.0000 - loss: 1.5016e-06 - val_accuracy: 1.0000 - val_loss: 8.7277e-07\n",
      "Epoch 287/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 976us/step - accuracy: 1.0000 - loss: 1.7383e-06 - val_accuracy: 1.0000 - val_loss: 8.4177e-07\n",
      "Epoch 288/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.8061e-06 - val_accuracy: 1.0000 - val_loss: 8.1459e-07\n",
      "Epoch 289/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 969us/step - accuracy: 1.0000 - loss: 1.3494e-06 - val_accuracy: 1.0000 - val_loss: 7.8757e-07\n",
      "Epoch 290/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.5508e-06 - val_accuracy: 1.0000 - val_loss: 7.6254e-07\n",
      "Epoch 291/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 988us/step - accuracy: 1.0000 - loss: 1.0047e-06 - val_accuracy: 1.0000 - val_loss: 7.3791e-07\n",
      "Epoch 292/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 993us/step - accuracy: 1.0000 - loss: 1.0405e-06 - val_accuracy: 1.0000 - val_loss: 7.1193e-07\n",
      "Epoch 293/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0623e-06 - val_accuracy: 1.0000 - val_loss: 6.9447e-07\n",
      "Epoch 294/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 961us/step - accuracy: 1.0000 - loss: 1.0970e-06 - val_accuracy: 1.0000 - val_loss: 6.6862e-07\n",
      "Epoch 295/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.2369e-06 - val_accuracy: 1.0000 - val_loss: 6.5307e-07\n",
      "Epoch 296/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 8.7388e-07 - val_accuracy: 1.0000 - val_loss: 6.2510e-07\n",
      "Epoch 297/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.2057e-06 - val_accuracy: 1.0000 - val_loss: 6.1752e-07\n",
      "Epoch 298/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 963us/step - accuracy: 1.0000 - loss: 1.0349e-06 - val_accuracy: 1.0000 - val_loss: 5.9276e-07\n",
      "Epoch 299/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996us/step - accuracy: 1.0000 - loss: 1.5037e-06 - val_accuracy: 1.0000 - val_loss: 5.7529e-07\n",
      "Epoch 300/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 9.7336e-07 - val_accuracy: 1.0000 - val_loss: 5.5974e-07\n",
      "Epoch 301/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 983us/step - accuracy: 1.0000 - loss: 7.7953e-07 - val_accuracy: 1.0000 - val_loss: 5.3944e-07\n",
      "Epoch 302/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.0709e-07 - val_accuracy: 1.0000 - val_loss: 5.2156e-07\n",
      "Epoch 303/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 7.4471e-07 - val_accuracy: 1.0000 - val_loss: 5.0522e-07\n",
      "Epoch 304/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.0274e-06 - val_accuracy: 1.0000 - val_loss: 4.9320e-07\n",
      "Epoch 305/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998us/step - accuracy: 1.0000 - loss: 1.1756e-06 - val_accuracy: 1.0000 - val_loss: 4.7598e-07\n",
      "Epoch 306/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 983us/step - accuracy: 1.0000 - loss: 8.2171e-07 - val_accuracy: 1.0000 - val_loss: 4.6146e-07\n",
      "Epoch 307/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989us/step - accuracy: 1.0000 - loss: 7.1403e-07 - val_accuracy: 1.0000 - val_loss: 4.4983e-07\n",
      "Epoch 308/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 977us/step - accuracy: 1.0000 - loss: 1.0189e-06 - val_accuracy: 1.0000 - val_loss: 4.3310e-07\n",
      "Epoch 309/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996us/step - accuracy: 1.0000 - loss: 7.2869e-07 - val_accuracy: 1.0000 - val_loss: 4.2137e-07\n",
      "Epoch 310/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.2249e-06 - val_accuracy: 1.0000 - val_loss: 4.0601e-07\n",
      "Epoch 311/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 5.6185e-07 - val_accuracy: 1.0000 - val_loss: 3.9157e-07\n",
      "Epoch 312/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 7.2394e-07 - val_accuracy: 1.0000 - val_loss: 3.8249e-07\n",
      "Epoch 313/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 6.8564e-07 - val_accuracy: 1.0000 - val_loss: 3.6959e-07\n",
      "Epoch 314/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 7.8764e-07 - val_accuracy: 1.0000 - val_loss: 3.5977e-07\n",
      "Epoch 315/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 8.3984e-07 - val_accuracy: 1.0000 - val_loss: 3.4727e-07\n",
      "Epoch 316/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 4.7226e-07 - val_accuracy: 1.0000 - val_loss: 3.3650e-07\n",
      "Epoch 317/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.0451e-06 - val_accuracy: 1.0000 - val_loss: 3.2590e-07\n",
      "Epoch 318/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 5.2326e-07 - val_accuracy: 1.0000 - val_loss: 3.1189e-07\n",
      "Epoch 319/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 994us/step - accuracy: 1.0000 - loss: 5.9912e-07 - val_accuracy: 1.0000 - val_loss: 3.0886e-07\n",
      "Epoch 320/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 980us/step - accuracy: 1.0000 - loss: 3.7622e-07 - val_accuracy: 1.0000 - val_loss: 2.9988e-07\n",
      "Epoch 321/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 6.3140e-07 - val_accuracy: 1.0000 - val_loss: 2.8965e-07\n",
      "Epoch 322/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - accuracy: 1.0000 - loss: 4.0919e-07 - val_accuracy: 1.0000 - val_loss: 2.8200e-07\n",
      "Epoch 323/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 6.0682e-07 - val_accuracy: 1.0000 - val_loss: 2.7201e-07\n",
      "Epoch 324/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 5.5428e-07 - val_accuracy: 1.0000 - val_loss: 2.6236e-07\n",
      "Epoch 325/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 4.7004e-07 - val_accuracy: 1.0000 - val_loss: 2.5689e-07\n",
      "Epoch 326/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 5.8491e-07 - val_accuracy: 1.0000 - val_loss: 2.4762e-07\n",
      "Epoch 327/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 965us/step - accuracy: 1.0000 - loss: 4.2314e-07 - val_accuracy: 1.0000 - val_loss: 2.4108e-07\n",
      "Epoch 328/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 7.8962e-07 - val_accuracy: 1.0000 - val_loss: 2.3239e-07\n",
      "Epoch 329/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 6.0081e-07 - val_accuracy: 1.0000 - val_loss: 2.2542e-07\n",
      "Epoch 330/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 8.9551e-07 - val_accuracy: 1.0000 - val_loss: 2.1848e-07\n",
      "Epoch 331/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.7424e-07 - val_accuracy: 1.0000 - val_loss: 2.1250e-07\n",
      "Epoch 332/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 4.9590e-07 - val_accuracy: 1.0000 - val_loss: 2.0500e-07\n",
      "Epoch 333/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 5.4053e-07 - val_accuracy: 1.0000 - val_loss: 2.0145e-07\n",
      "Epoch 334/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 3.8950e-07 - val_accuracy: 1.0000 - val_loss: 1.9602e-07\n",
      "Epoch 335/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 3.7861e-07 - val_accuracy: 1.0000 - val_loss: 1.8835e-07\n",
      "Epoch 336/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 4.6691e-07 - val_accuracy: 1.0000 - val_loss: 1.8382e-07\n",
      "Epoch 337/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 3.8504e-07 - val_accuracy: 1.0000 - val_loss: 1.7771e-07\n",
      "Epoch 338/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.2656e-07 - val_accuracy: 1.0000 - val_loss: 1.7235e-07\n",
      "Epoch 339/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 3.7184e-07 - val_accuracy: 1.0000 - val_loss: 1.6788e-07\n",
      "Epoch 340/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 987us/step - accuracy: 1.0000 - loss: 2.6981e-07 - val_accuracy: 1.0000 - val_loss: 1.6346e-07\n",
      "Epoch 341/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step - accuracy: 1.0000 - loss: 3.7285e-07 - val_accuracy: 1.0000 - val_loss: 1.5839e-07\n",
      "Epoch 342/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 3.4934e-07 - val_accuracy: 1.0000 - val_loss: 1.5343e-07\n",
      "Epoch 343/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 3.3174e-07 - val_accuracy: 1.0000 - val_loss: 1.4876e-07\n",
      "Epoch 344/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step - accuracy: 1.0000 - loss: 5.3679e-07 - val_accuracy: 1.0000 - val_loss: 1.4419e-07\n",
      "Epoch 345/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 3.7094e-07 - val_accuracy: 1.0000 - val_loss: 1.4035e-07\n",
      "Epoch 346/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.2659e-07 - val_accuracy: 1.0000 - val_loss: 1.3477e-07\n",
      "Epoch 347/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.1710e-07 - val_accuracy: 1.0000 - val_loss: 1.3293e-07\n",
      "Epoch 348/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step - accuracy: 1.0000 - loss: 2.4332e-07 - val_accuracy: 1.0000 - val_loss: 1.2924e-07\n",
      "Epoch 349/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 3.1413e-07 - val_accuracy: 1.0000 - val_loss: 1.2515e-07\n",
      "Epoch 350/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 983us/step - accuracy: 1.0000 - loss: 2.1383e-07 - val_accuracy: 1.0000 - val_loss: 1.2201e-07\n",
      "Epoch 351/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 5.5003e-07 - val_accuracy: 1.0000 - val_loss: 1.1779e-07\n",
      "Epoch 352/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.6323e-07 - val_accuracy: 1.0000 - val_loss: 1.1338e-07\n",
      "Epoch 353/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.6807e-07 - val_accuracy: 1.0000 - val_loss: 1.1156e-07\n",
      "Epoch 354/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8809e-07 - val_accuracy: 1.0000 - val_loss: 1.0894e-07\n",
      "Epoch 355/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step - accuracy: 1.0000 - loss: 4.1081e-07 - val_accuracy: 1.0000 - val_loss: 1.0549e-07\n",
      "Epoch 356/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.0315e-07 - val_accuracy: 1.0000 - val_loss: 1.0250e-07\n",
      "Epoch 357/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.4105e-07 - val_accuracy: 1.0000 - val_loss: 9.9785e-08\n",
      "Epoch 358/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.2789e-07 - val_accuracy: 1.0000 - val_loss: 9.6893e-08\n",
      "Epoch 359/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 994us/step - accuracy: 1.0000 - loss: 2.5784e-07 - val_accuracy: 1.0000 - val_loss: 9.3861e-08\n",
      "Epoch 360/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.0781e-07 - val_accuracy: 1.0000 - val_loss: 9.1595e-08\n",
      "Epoch 361/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.2779e-07 - val_accuracy: 1.0000 - val_loss: 8.8811e-08\n",
      "Epoch 362/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8761e-07 - val_accuracy: 1.0000 - val_loss: 8.6226e-08\n",
      "Epoch 363/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 973us/step - accuracy: 1.0000 - loss: 2.3537e-07 - val_accuracy: 1.0000 - val_loss: 8.3936e-08\n",
      "Epoch 364/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.7418e-07 - val_accuracy: 1.0000 - val_loss: 8.1573e-08\n",
      "Epoch 365/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.9698e-07 - val_accuracy: 1.0000 - val_loss: 7.9942e-08\n",
      "Epoch 366/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.7124e-07 - val_accuracy: 1.0000 - val_loss: 7.7594e-08\n",
      "Epoch 367/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 980us/step - accuracy: 1.0000 - loss: 2.3097e-07 - val_accuracy: 1.0000 - val_loss: 7.5129e-08\n",
      "Epoch 368/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 3.7506e-07 - val_accuracy: 1.0000 - val_loss: 7.3761e-08\n",
      "Epoch 369/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.3561e-07 - val_accuracy: 1.0000 - val_loss: 7.0706e-08\n",
      "Epoch 370/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.8086e-07 - val_accuracy: 1.0000 - val_loss: 6.8872e-08\n",
      "Epoch 371/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 3.7551e-07 - val_accuracy: 1.0000 - val_loss: 6.7214e-08\n",
      "Epoch 372/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 990us/step - accuracy: 1.0000 - loss: 1.1747e-07 - val_accuracy: 1.0000 - val_loss: 6.5498e-08\n",
      "Epoch 373/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.8996e-07 - val_accuracy: 1.0000 - val_loss: 6.3740e-08\n",
      "Epoch 374/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 983us/step - accuracy: 1.0000 - loss: 1.0201e-07 - val_accuracy: 1.0000 - val_loss: 6.2516e-08\n",
      "Epoch 375/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.4128e-07 - val_accuracy: 1.0000 - val_loss: 6.0671e-08\n",
      "Epoch 376/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2465e-07 - val_accuracy: 1.0000 - val_loss: 5.8923e-08\n",
      "Epoch 377/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.2695e-07 - val_accuracy: 1.0000 - val_loss: 5.7460e-08\n",
      "Epoch 378/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.5318e-07 - val_accuracy: 1.0000 - val_loss: 5.5961e-08\n",
      "Epoch 379/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.2255e-07 - val_accuracy: 1.0000 - val_loss: 5.4859e-08\n",
      "Epoch 380/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.0368e-07 - val_accuracy: 1.0000 - val_loss: 5.2947e-08\n",
      "Epoch 381/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.0915e-07 - val_accuracy: 1.0000 - val_loss: 5.1545e-08\n",
      "Epoch 382/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.5921e-07 - val_accuracy: 1.0000 - val_loss: 5.0331e-08\n",
      "Epoch 383/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4456e-07 - val_accuracy: 1.0000 - val_loss: 4.9077e-08\n",
      "Epoch 384/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.1053e-07 - val_accuracy: 1.0000 - val_loss: 4.7869e-08\n",
      "Epoch 385/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.3053e-07 - val_accuracy: 1.0000 - val_loss: 4.6821e-08\n",
      "Epoch 386/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989us/step - accuracy: 1.0000 - loss: 1.3883e-07 - val_accuracy: 1.0000 - val_loss: 4.5780e-08\n",
      "Epoch 387/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 7.1630e-08 - val_accuracy: 1.0000 - val_loss: 4.3902e-08\n",
      "Epoch 388/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 9.3854e-08 - val_accuracy: 1.0000 - val_loss: 4.3294e-08\n",
      "Epoch 389/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 9.5936e-08 - val_accuracy: 1.0000 - val_loss: 4.2223e-08\n",
      "Epoch 390/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.8484e-07 - val_accuracy: 1.0000 - val_loss: 4.1220e-08\n",
      "Epoch 391/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 7.9477e-08 - val_accuracy: 1.0000 - val_loss: 4.0774e-08\n",
      "Epoch 392/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 976us/step - accuracy: 1.0000 - loss: 7.9532e-08 - val_accuracy: 1.0000 - val_loss: 3.8880e-08\n",
      "Epoch 393/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1775e-07 - val_accuracy: 1.0000 - val_loss: 3.8260e-08\n",
      "Epoch 394/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.0849e-07 - val_accuracy: 1.0000 - val_loss: 3.7318e-08\n",
      "Epoch 395/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step - accuracy: 1.0000 - loss: 7.3486e-08 - val_accuracy: 1.0000 - val_loss: 3.6622e-08\n",
      "Epoch 396/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 979us/step - accuracy: 1.0000 - loss: 1.4085e-07 - val_accuracy: 1.0000 - val_loss: 3.5464e-08\n",
      "Epoch 397/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 985us/step - accuracy: 1.0000 - loss: 1.1326e-07 - val_accuracy: 1.0000 - val_loss: 3.4432e-08\n",
      "Epoch 398/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 6.2853e-08 - val_accuracy: 1.0000 - val_loss: 3.3452e-08\n",
      "Epoch 399/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.7270e-07 - val_accuracy: 1.0000 - val_loss: 3.2905e-08\n",
      "Epoch 400/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 9.8070e-08 - val_accuracy: 1.0000 - val_loss: 3.2177e-08\n",
      "Epoch 401/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.3761e-08 - val_accuracy: 1.0000 - val_loss: 3.1383e-08\n",
      "Epoch 402/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 995us/step - accuracy: 1.0000 - loss: 1.6641e-07 - val_accuracy: 1.0000 - val_loss: 3.0655e-08\n",
      "Epoch 403/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.5780e-07 - val_accuracy: 1.0000 - val_loss: 2.9832e-08\n",
      "Epoch 404/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 9.5873e-08 - val_accuracy: 1.0000 - val_loss: 2.9140e-08\n",
      "Epoch 405/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.0135e-07 - val_accuracy: 1.0000 - val_loss: 2.8475e-08\n",
      "Epoch 406/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 4.1679e-08 - val_accuracy: 1.0000 - val_loss: 2.7787e-08\n",
      "Epoch 407/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 7.3079e-08 - val_accuracy: 1.0000 - val_loss: 2.7245e-08\n",
      "Epoch 408/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.8426e-08 - val_accuracy: 1.0000 - val_loss: 2.6592e-08\n",
      "Epoch 409/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.0947e-07 - val_accuracy: 1.0000 - val_loss: 2.6028e-08\n",
      "Epoch 410/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999us/step - accuracy: 1.0000 - loss: 6.8071e-08 - val_accuracy: 1.0000 - val_loss: 2.5430e-08\n",
      "Epoch 411/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 7.4955e-08 - val_accuracy: 1.0000 - val_loss: 2.4814e-08\n",
      "Epoch 412/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 958us/step - accuracy: 1.0000 - loss: 6.2367e-08 - val_accuracy: 1.0000 - val_loss: 2.4236e-08\n",
      "Epoch 413/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 5.3277e-08 - val_accuracy: 1.0000 - val_loss: 2.3785e-08\n",
      "Epoch 414/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 7.0848e-08 - val_accuracy: 1.0000 - val_loss: 2.3249e-08\n",
      "Epoch 415/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.3780e-07 - val_accuracy: 1.0000 - val_loss: 2.2686e-08\n",
      "Epoch 416/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 986us/step - accuracy: 1.0000 - loss: 8.6487e-08 - val_accuracy: 1.0000 - val_loss: 2.2213e-08\n",
      "Epoch 417/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 4.9565e-08 - val_accuracy: 1.0000 - val_loss: 2.1641e-08\n",
      "Epoch 418/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2320e-07 - val_accuracy: 1.0000 - val_loss: 2.1169e-08\n",
      "Epoch 419/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 6.3695e-08 - val_accuracy: 1.0000 - val_loss: 2.0646e-08\n",
      "Epoch 420/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 7.1874e-08 - val_accuracy: 1.0000 - val_loss: 2.0265e-08\n",
      "Epoch 421/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 5.9327e-08 - val_accuracy: 1.0000 - val_loss: 1.9833e-08\n",
      "Epoch 422/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989us/step - accuracy: 1.0000 - loss: 7.1484e-08 - val_accuracy: 1.0000 - val_loss: 1.9462e-08\n",
      "Epoch 423/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998us/step - accuracy: 1.0000 - loss: 4.9449e-08 - val_accuracy: 1.0000 - val_loss: 1.9193e-08\n",
      "Epoch 424/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 975us/step - accuracy: 1.0000 - loss: 6.9883e-08 - val_accuracy: 1.0000 - val_loss: 1.8547e-08\n",
      "Epoch 425/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.2542e-07 - val_accuracy: 1.0000 - val_loss: 1.8101e-08\n",
      "Epoch 426/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 7.9671e-08 - val_accuracy: 1.0000 - val_loss: 1.7674e-08\n",
      "Epoch 427/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 4.9024e-08 - val_accuracy: 1.0000 - val_loss: 1.7440e-08\n",
      "Epoch 428/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989us/step - accuracy: 1.0000 - loss: 4.0354e-08 - val_accuracy: 1.0000 - val_loss: 1.6942e-08\n",
      "Epoch 429/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 4.7197e-08 - val_accuracy: 1.0000 - val_loss: 1.6750e-08\n",
      "Epoch 430/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 5.1654e-08 - val_accuracy: 1.0000 - val_loss: 1.6326e-08\n",
      "Epoch 431/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 982us/step - accuracy: 1.0000 - loss: 5.0536e-08 - val_accuracy: 1.0000 - val_loss: 1.6029e-08\n",
      "Epoch 432/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 990us/step - accuracy: 1.0000 - loss: 5.5960e-08 - val_accuracy: 1.0000 - val_loss: 1.5698e-08\n",
      "Epoch 433/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.5499e-08 - val_accuracy: 1.0000 - val_loss: 1.5382e-08\n",
      "Epoch 434/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 3.5731e-08 - val_accuracy: 1.0000 - val_loss: 1.5119e-08\n",
      "Epoch 435/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989us/step - accuracy: 1.0000 - loss: 5.7836e-08 - val_accuracy: 1.0000 - val_loss: 1.4761e-08\n",
      "Epoch 436/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 8.2615e-08 - val_accuracy: 1.0000 - val_loss: 1.4483e-08\n",
      "Epoch 437/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.0812e-08 - val_accuracy: 1.0000 - val_loss: 1.4266e-08\n",
      "Epoch 438/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.9943e-08 - val_accuracy: 1.0000 - val_loss: 1.3943e-08\n",
      "Epoch 439/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 4.9035e-08 - val_accuracy: 1.0000 - val_loss: 1.3616e-08\n",
      "Epoch 440/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 8.3703e-08 - val_accuracy: 1.0000 - val_loss: 1.3314e-08\n",
      "Epoch 441/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 3.5892e-08 - val_accuracy: 1.0000 - val_loss: 1.3070e-08\n",
      "Epoch 442/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 3.9093e-08 - val_accuracy: 1.0000 - val_loss: 1.2803e-08\n",
      "Epoch 443/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 5.7249e-08 - val_accuracy: 1.0000 - val_loss: 1.2562e-08\n",
      "Epoch 444/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.8269e-08 - val_accuracy: 1.0000 - val_loss: 1.2326e-08\n",
      "Epoch 445/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 4.3450e-08 - val_accuracy: 1.0000 - val_loss: 1.2094e-08\n",
      "Epoch 446/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 5.5056e-08 - val_accuracy: 1.0000 - val_loss: 1.1845e-08\n",
      "Epoch 447/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 3.9162e-08 - val_accuracy: 1.0000 - val_loss: 1.1643e-08\n",
      "Epoch 448/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 8.2080e-08 - val_accuracy: 1.0000 - val_loss: 1.1392e-08\n",
      "Epoch 449/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 3.2481e-08 - val_accuracy: 1.0000 - val_loss: 1.1144e-08\n",
      "Epoch 450/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 7.1330e-08 - val_accuracy: 1.0000 - val_loss: 1.0972e-08\n",
      "Epoch 451/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.7213e-08 - val_accuracy: 1.0000 - val_loss: 1.0763e-08\n",
      "Epoch 452/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 3.7828e-08 - val_accuracy: 1.0000 - val_loss: 1.0578e-08\n",
      "Epoch 453/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 4.8010e-08 - val_accuracy: 1.0000 - val_loss: 1.0396e-08\n",
      "Epoch 454/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.8462e-08 - val_accuracy: 1.0000 - val_loss: 1.0190e-08\n",
      "Epoch 455/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.6010e-08 - val_accuracy: 1.0000 - val_loss: 9.9813e-09\n",
      "Epoch 456/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.9486e-08 - val_accuracy: 1.0000 - val_loss: 9.7995e-09\n",
      "Epoch 457/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.3945e-08 - val_accuracy: 1.0000 - val_loss: 9.6581e-09\n",
      "Epoch 458/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.4379e-08 - val_accuracy: 1.0000 - val_loss: 9.4546e-09\n",
      "Epoch 459/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 7.9843e-08 - val_accuracy: 1.0000 - val_loss: 9.3268e-09\n",
      "Epoch 460/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 4.1740e-08 - val_accuracy: 1.0000 - val_loss: 9.1536e-09\n",
      "Epoch 461/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.1043e-08 - val_accuracy: 1.0000 - val_loss: 9.0848e-09\n",
      "Epoch 462/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.0770e-08 - val_accuracy: 1.0000 - val_loss: 8.8076e-09\n",
      "Epoch 463/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.0054e-08 - val_accuracy: 1.0000 - val_loss: 8.6826e-09\n",
      "Epoch 464/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3951e-08 - val_accuracy: 1.0000 - val_loss: 8.6053e-09\n",
      "Epoch 465/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.4946e-08 - val_accuracy: 1.0000 - val_loss: 8.3900e-09\n",
      "Epoch 466/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 3.2593e-08 - val_accuracy: 1.0000 - val_loss: 8.2171e-09\n",
      "Epoch 467/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.7520e-08 - val_accuracy: 1.0000 - val_loss: 8.1326e-09\n",
      "Epoch 468/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.4839e-08 - val_accuracy: 1.0000 - val_loss: 7.9485e-09\n",
      "Epoch 469/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 5.7587e-08 - val_accuracy: 1.0000 - val_loss: 7.8564e-09\n",
      "Epoch 470/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 3.0313e-08 - val_accuracy: 1.0000 - val_loss: 7.7034e-09\n",
      "Epoch 471/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.8095e-08 - val_accuracy: 1.0000 - val_loss: 7.5646e-09\n",
      "Epoch 472/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.0937e-08 - val_accuracy: 1.0000 - val_loss: 7.4475e-09\n",
      "Epoch 473/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 8.3315e-08 - val_accuracy: 1.0000 - val_loss: 7.3252e-09\n",
      "Epoch 474/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.6571e-08 - val_accuracy: 1.0000 - val_loss: 7.2375e-09\n",
      "Epoch 475/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.1885e-08 - val_accuracy: 1.0000 - val_loss: 7.0632e-09\n",
      "Epoch 476/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.5273e-08 - val_accuracy: 1.0000 - val_loss: 6.9814e-09\n",
      "Epoch 477/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.5070e-08 - val_accuracy: 1.0000 - val_loss: 6.8542e-09\n",
      "Epoch 478/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.9482e-08 - val_accuracy: 1.0000 - val_loss: 6.7732e-09\n",
      "Epoch 479/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 4.0853e-08 - val_accuracy: 1.0000 - val_loss: 6.6651e-09\n",
      "Epoch 480/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 5.4586e-08 - val_accuracy: 1.0000 - val_loss: 6.5107e-09\n",
      "Epoch 481/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.0893e-08 - val_accuracy: 1.0000 - val_loss: 6.4812e-09\n",
      "Epoch 482/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.3305e-08 - val_accuracy: 1.0000 - val_loss: 6.2920e-09\n",
      "Epoch 483/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9392e-08 - val_accuracy: 1.0000 - val_loss: 6.1950e-09\n",
      "Epoch 484/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0038e-08 - val_accuracy: 1.0000 - val_loss: 6.0957e-09\n",
      "Epoch 485/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.1321e-08 - val_accuracy: 1.0000 - val_loss: 6.0110e-09\n",
      "Epoch 486/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.8052e-08 - val_accuracy: 1.0000 - val_loss: 5.9231e-09\n",
      "Epoch 487/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.3021e-08 - val_accuracy: 1.0000 - val_loss: 5.8298e-09\n",
      "Epoch 488/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.8877e-08 - val_accuracy: 1.0000 - val_loss: 5.7803e-09\n",
      "Epoch 489/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.6307e-08 - val_accuracy: 1.0000 - val_loss: 5.6695e-09\n",
      "Epoch 490/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 7.9380e-09 - val_accuracy: 1.0000 - val_loss: 5.5818e-09\n",
      "Epoch 491/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.1521e-08 - val_accuracy: 1.0000 - val_loss: 5.4885e-09\n",
      "Epoch 492/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.7055e-08 - val_accuracy: 1.0000 - val_loss: 5.4164e-09\n",
      "Epoch 493/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 3.4904e-08 - val_accuracy: 1.0000 - val_loss: 5.3447e-09\n",
      "Epoch 494/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.9093e-08 - val_accuracy: 1.0000 - val_loss: 5.2581e-09\n",
      "Epoch 495/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.0081e-08 - val_accuracy: 1.0000 - val_loss: 5.1862e-09\n",
      "Epoch 496/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.6710e-08 - val_accuracy: 1.0000 - val_loss: 5.0993e-09\n",
      "Epoch 497/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.0360e-08 - val_accuracy: 1.0000 - val_loss: 5.0356e-09\n",
      "Epoch 498/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.6072e-08 - val_accuracy: 1.0000 - val_loss: 4.9744e-09\n",
      "Epoch 499/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 3.3715e-08 - val_accuracy: 1.0000 - val_loss: 4.9195e-09\n",
      "Epoch 500/500\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.8886e-08 - val_accuracy: 1.0000 - val_loss: 4.8467e-09\n"
     ]
    }
   ],
   "source": [
    "# Freeze all layers except the last layer (or last few layers if you want to fine-tune more)\n",
    "for layer in base_model.layers[:-1]:  # Adjust this to control how many layers to freeze\n",
    "    layer.trainable = False\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Remove the last layer\n",
    "base_model.pop()\n",
    "\n",
    "# Add new layers with unique names\n",
    "base_model.add(Dense(64, activation='relu', name='dense_finetune_2'))  # Unique name for added hidden layer\n",
    "base_model.add(Dense(1, activation='sigmoid', name='dense_output_finetune'))  # Unique name for output layer\n",
    "\n",
    "# Compile the model with a low learning rate for fine-tuning\n",
    "base_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Compile the model with a low learning rate for fine-tuning\n",
    "base_model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "history = base_model.fit(X_train, y_train, epochs=500, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hthnh/.local/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "# Example new sensor readings (CO, VOC, Temp, Hum)\n",
    "new_data = np.array([[40, 50, 30.2, 72.5]])  # Example values for testing\n",
    "scaler = joblib.load('/home/hthnh/Desktop/project-khkt-thcs/model/scaler.pkl')\n",
    "# Assuming you used a scaler for normalization during training\n",
    "new_data_scaled = scaler.transform(new_data)  # Normalize the new data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Normal environment\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "prediction = base_model.predict(new_data_scaled)\n",
    "\n",
    "# Interpret the prediction (assuming binary classification: 0 = normal, 1 = smoke)\n",
    "if prediction[0][0] > 0.5:\n",
    "    print(\"Smoke detected\")\n",
    "else:\n",
    "    print(\"Normal environment\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
